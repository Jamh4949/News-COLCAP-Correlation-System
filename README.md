# ğŸ“Š News-COLCAP Correlation System

Sistema distribuido para analizar correlaciones entre noticias y el Ã­ndice bursÃ¡til COLCAP utilizando tecnologÃ­as de contenedores y Kubernetes.

## ğŸ¯ Objetivos del Proyecto

- Procesamiento distribuido de noticias en tiempo real usando GDELT
- AnÃ¡lisis de correlaciÃ³n con indicadores econÃ³micos (COLCAP)
- Despliegue en Kubernetes (EKS/k3s)
- Arquitectura de microservicios escalable
- **ParalelizaciÃ³n real** con ProcessPoolExecutor y ThreadPoolExecutor

## âš¡ CaracterÃ­sticas de ParalelizaciÃ³n y DistribuciÃ³n

### Procesamiento Paralelo
| Servicio | TÃ©cnica | Beneficio |
|----------|---------|-----------|
| **Collector** | Batch Inserts (execute_values) | 10x mÃ¡s rÃ¡pido en BD |
| **Processor** | ThreadPoolExecutor + Bloqueo Distribuido | Procesamiento multi-thread sin duplicados |
| **Analyzer** | ThreadPoolExecutor | I/O paralelo (Yahoo Finance + BD) |
| **API** | MÃ©tricas Prometheus | Observabilidad en tiempo real |

### Kubernetes Distribuido
- **HorizontalPodAutoscaler**: Escala pods automÃ¡ticamente por CPU/memoria
- **PodDisruptionBudget**: Alta disponibilidad garantizada
- **Jobs Paralelos**: Procesamiento batch con `parallelism` y `completions`
- **CronJobs**: Tareas programadas distribuidas

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Kubernetes Cluster (EKS/k3s)                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  GDELT       â”‚   â”‚  Processing       â”‚   â”‚  Analysis       â”‚ â”‚
â”‚  â”‚  Collector   â”‚â”€â”€â–¶â”‚  Service (x3)     â”‚â”€â”€â–¶â”‚  Service        â”‚ â”‚
â”‚  â”‚  Batch Insertâ”‚   â”‚  ProcessPool      â”‚   â”‚  ThreadPool     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  FOR UPDATE SKIP  â”‚   â”‚  Parallel I/O   â”‚ â”‚
â”‚         â”‚           â”‚  LOCKED           â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                    â–¼                                              â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚         â”‚  Redis (Cache/Queue) â”‚    â”‚  Prometheus (Metrics)   â”‚ â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                    â”‚                          â–²                   â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚                  â”‚
â”‚         â–¼                     â–¼               â”‚                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚                  â”‚
â”‚  â”‚ PostgreSQL  â”‚      â”‚  FastAPI +    â”‚â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚  â”‚ (Container) â”‚      â”‚  Dashboard    â”‚  /metrics               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  HPA (x2-5)   â”‚                         â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Estructura del Proyecto

```
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ collector/          # Servicio recolector GDELT (Batch Insert)
â”‚   â”œâ”€â”€ processor/          # Servicio ETL (ProcessPoolExecutor)
â”‚   â”œâ”€â”€ analyzer/           # Servicio anÃ¡lisis (ThreadPoolExecutor)
â”‚   â””â”€â”€ api/                # API REST + Dashboard + Prometheus
â”œâ”€â”€ k8s/                    # Manifiestos de Kubernetes
â”‚   â”œâ”€â”€ 07-processor.yaml   # HPA, PDB, 3 rÃ©plicas
â”‚   â”œâ”€â”€ 08-analyzer.yaml    # CronJob para anÃ¡lisis
â”‚   â”œâ”€â”€ 09-api.yaml         # HPA, PDB, mÃ©tricas
â”‚   â”œâ”€â”€ 10-batch-processing-job.yaml  # Jobs paralelos
â”‚   â””â”€â”€ 11-prometheus.yaml  # Observabilidad
â”œâ”€â”€ database/               # Scripts de base de datos
â”œâ”€â”€ scripts/                # Scripts de despliegue
â”œâ”€â”€ data/                   # Datos de referencia COLCAP
â”œâ”€â”€ docker-compose.yml      # Para desarrollo local (USAR ESTO)
â””â”€â”€ README.md
```

## ğŸš€ Stack TecnolÃ³gico

- **Cloud**: AWS (EKS) / Oracle Cloud (k3s)
- **OrquestaciÃ³n**: Kubernetes con HPA y PDB
- **Lenguaje**: Python 3.11
- **ParalelizaciÃ³n**: ProcessPoolExecutor, ThreadPoolExecutor
- **Web Framework**: FastAPI
- **Base de datos**: PostgreSQL 15 (Batch Operations)
- **Cache/Queue**: Redis 7
- **Observabilidad**: Prometheus + endpoint /metrics
- **Fuente de datos**: GDELT Project + Yahoo Finance

## ğŸ“¦ InstalaciÃ³n y Uso

### Prerrequisitos
- Docker y Docker Compose
- kubectl (para Kubernetes)

### ğŸš€ EjecuciÃ³n Local con Docker (PARA COMPAÃ‘EROS)

```powershell
# 1. Clonar el repositorio
git clone <repo-url>
cd news-colcap

# 2. Construir las imÃ¡genes Docker
docker-compose build

# 3. Levantar TODOS los servicios con 3 processors paralelos
docker-compose up -d --scale processor=3

# 4. Ver los logs de los processors en paralelo
docker-compose logs -f processor

# 5. Acceder al Dashboard
start http://localhost:8000

# 6. Ver mÃ©tricas Prometheus
start http://localhost:8000/metrics
```

### â¹ï¸ Detener el Sistema
```powershell
docker-compose down
```

### ğŸ“Š Verificar ParalelizaciÃ³n
```powershell
# Ver las 3 instancias del processor corriendo
docker-compose ps

# Ver logs de procesamiento paralelo en tiempo real
docker-compose logs -f processor

# DeberÃ­as ver logs de processor-1, processor-2, processor-3
# procesando artÃ­culos simultÃ¡neamente
```

### Despliegue en Kubernetes

```bash
# 1. Aplicar manifiestos
kubectl apply -f k8s/

# 2. Verificar pods escalados
kubectl get pods -n news-colcap

# 3. Ver HPA en acciÃ³n
kubectl get hpa -n news-colcap

# 4. Ejecutar Job de procesamiento paralelo
kubectl apply -f k8s/10-batch-processing-job.yaml

# 5. Ver mÃ©tricas
kubectl port-forward svc/api-service 8000:8000 -n news-colcap
curl http://localhost:8000/metrics
```

## ğŸ“Š Servicios

### 1. Collector Service
- Recolecta noticias de GDELT cada 6 horas
- **BATCH INSERT**: Inserta 500 registros por operaciÃ³n
- Filtra noticias relacionadas con Colombia

### 2. Processor Service (Paralelo)
- **ThreadPoolExecutor**: AnÃ¡lisis de sentimiento multi-thread (32+ threads)
- **FOR UPDATE SKIP LOCKED**: Bloqueo distribuido para pods mÃºltiples
- **BATCH UPDATE**: Actualiza 100 registros por operaciÃ³n
- Escala automÃ¡ticamente de 2 a 6 pods (HPA)

### 3. Analyzer Service (Paralelo)
- **ThreadPoolExecutor**: Fetch paralelo Yahoo Finance + BD
- Calcula correlaciones Pearson/Spearman
- CronJob para anÃ¡lisis programado cada 6 horas

### 4. API & Dashboard
- Endpoints REST para consultas
- **Endpoint /metrics**: Formato Prometheus
- VisualizaciÃ³n de correlaciones
- Escala automÃ¡ticamente de 2 a 5 pods (HPA)

## ğŸ“ˆ MÃ©tricas y Observabilidad

### Endpoint Prometheus `/metrics`
```
news_colcap_news_total          # Total de noticias recolectadas
news_colcap_news_processed      # Noticias con anÃ¡lisis de sentimiento
news_colcap_news_pending        # Noticias pendientes de procesar
news_colcap_sentiment_positive  # Noticias positivas
news_colcap_sentiment_negative  # Noticias negativas
news_colcap_sentiment_average   # Sentimiento promedio
news_colcap_colcap_price        # Precio COLCAP actual
news_colcap_redis_up            # Estado de Redis
```

### Prueba de Rendimiento
```powershell
# Ejecutar prueba de procesamiento paralelo
python test_parallel_processing.py

# Resultado esperado:
# - 50 artÃ­culos procesados
# - Tiempo: ~5-10 segundos
# - Velocidad: 5-10 artÃ­culos/segundo
```

## ğŸ”§ Escalabilidad Kubernetes

### Escalar Manualmente
```bash
# Escalar processors a 5 rÃ©plicas
kubectl scale deployment processor --replicas=5 -n news-colcap

# Ver autoescalado
kubectl get hpa -n news-colcap -w
```

### Ejecutar Job Paralelo
```bash
# Job con 5 completions y 3 en paralelo
kubectl apply -f k8s/10-batch-processing-job.yaml

# Ver progreso
kubectl get jobs -n news-colcap
kubectl logs -f job/news-batch-processor -n news-colcap
```

### Tolerancia a Fallos
```bash
# Matar un pod y ver recuperaciÃ³n
kubectl delete pod processor-xxxxx -n news-colcap

# El HPA y el Deployment recrean el pod automÃ¡ticamente
kubectl get pods -n news-colcap -w
```

## ğŸ‘¥ Equipo

- Jose Armando MartÃ­nez HernÃ¡ndez - 2325365

## ğŸ“„ License

This project is **dual-licensed**:

- **Non-commercial use** is allowed with attribution.
- **Commercial use** requires a separate license and may be subject to fees or royalties.

See the [LICENSE](./LICENSE) file for details.
