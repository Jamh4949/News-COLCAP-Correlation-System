# üìä News-COLCAP Correlation System

Sistema distribuido para analizar correlaciones entre noticias y el √≠ndice burs√°til COLCAP utilizando tecnolog√≠as de contenedores y Kubernetes.

## üéØ Objetivos del Proyecto

- Procesamiento distribuido de noticias en tiempo real usando GDELT
- An√°lisis de correlaci√≥n con indicadores econ√≥micos (COLCAP)
- Despliegue en Kubernetes (EKS/k3s)
- Arquitectura de microservicios escalable
- **Paralelizaci√≥n real** con ProcessPoolExecutor y ThreadPoolExecutor

## ‚ö° Caracter√≠sticas de Paralelizaci√≥n y Distribuci√≥n

### Procesamiento Paralelo
| Servicio | T√©cnica | Beneficio |
|----------|---------|-----------|
| **Collector** | Batch Inserts (execute_values) | 10x m√°s r√°pido en BD |
| **Processor** | ThreadPoolExecutor + Bloqueo Distribuido | Procesamiento multi-thread sin duplicados |
| **Analyzer** | ThreadPoolExecutor | I/O paralelo (Yahoo Finance + BD) |
| **API** | M√©tricas Prometheus | Observabilidad en tiempo real |

### Kubernetes Distribuido
- **HorizontalPodAutoscaler**: Escala pods autom√°ticamente por CPU/memoria
- **PodDisruptionBudget**: Alta disponibilidad garantizada
- **Jobs Paralelos**: Procesamiento batch con `parallelism` y `completions`
- **CronJobs**: Tareas programadas distribuidas

## üèóÔ∏è Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    Kubernetes Cluster (EKS/k3s)                                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  GDELT       ‚îÇ   ‚îÇ  Processing       ‚îÇ   ‚îÇ  Analysis       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  Collector   ‚îÇ‚îÄ‚îÄ‚ñ∂‚îÇ  Service (x3)     ‚îÇ‚îÄ‚îÄ‚ñ∂‚îÇ  Service        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  Batch Insert‚îÇ   ‚îÇ  ProcessPool      ‚îÇ   ‚îÇ  ThreadPool     ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ  FOR UPDATE SKIP  ‚îÇ   ‚îÇ  Parallel I/O   ‚îÇ ‚îÇ
‚îÇ         ‚îÇ           ‚îÇ  LOCKED           ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ         ‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ            ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îÇ                    ‚ñº                                              ‚îÇ
‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ         ‚îÇ  Redis (Cache/Queue) ‚îÇ    ‚îÇ  Prometheus (Metrics)   ‚îÇ ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                    ‚îÇ                          ‚ñ≤                   ‚îÇ
‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ                  ‚îÇ
‚îÇ         ‚ñº                     ‚ñº               ‚îÇ                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ                  ‚îÇ
‚îÇ  ‚îÇ PostgreSQL  ‚îÇ      ‚îÇ  FastAPI +    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ
‚îÇ  ‚îÇ (Container) ‚îÇ      ‚îÇ  Dashboard    ‚îÇ  /metrics               ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ  HPA (x2-5)   ‚îÇ                         ‚îÇ
‚îÇ                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìÅ Estructura del Proyecto

```
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ collector/          # Servicio recolector GDELT (Batch Insert)
‚îÇ   ‚îú‚îÄ‚îÄ processor/          # Servicio ETL (ProcessPoolExecutor)
‚îÇ   ‚îú‚îÄ‚îÄ analyzer/           # Servicio an√°lisis (ThreadPoolExecutor)
‚îÇ   ‚îî‚îÄ‚îÄ api/                # API REST + Dashboard + Prometheus
‚îú‚îÄ‚îÄ k8s/                    # Manifiestos de Kubernetes
‚îÇ   ‚îú‚îÄ‚îÄ 07-processor.yaml   # HPA, PDB, 3 r√©plicas
‚îÇ   ‚îú‚îÄ‚îÄ 08-analyzer.yaml    # CronJob para an√°lisis
‚îÇ   ‚îú‚îÄ‚îÄ 09-api.yaml         # HPA, PDB, m√©tricas
‚îÇ   ‚îú‚îÄ‚îÄ 10-batch-processing-job.yaml  # Jobs paralelos
‚îÇ   ‚îî‚îÄ‚îÄ 11-prometheus.yaml  # Observabilidad
‚îú‚îÄ‚îÄ database/               # Scripts de base de datos
‚îú‚îÄ‚îÄ scripts/                # Scripts de despliegue
‚îú‚îÄ‚îÄ data/                   # Datos de referencia COLCAP
‚îú‚îÄ‚îÄ docker-compose.yml      # Para desarrollo local (USAR ESTO)
‚îî‚îÄ‚îÄ README.md
```

## üöÄ Stack Tecnol√≥gico

- **Cloud**: AWS (EKS) / Oracle Cloud (k3s)
- **Orquestaci√≥n**: Kubernetes con HPA y PDB
- **Lenguaje**: Python 3.11
- **Paralelizaci√≥n**: ProcessPoolExecutor, ThreadPoolExecutor
- **Web Framework**: FastAPI
- **Base de datos**: PostgreSQL 15 (Batch Operations)
- **Cache/Queue**: Redis 7
- **Observabilidad**: Prometheus + endpoint /metrics
- **Fuente de datos**: GDELT Project + Yahoo Finance

## üì¶ Instalaci√≥n y Uso

### Prerrequisitos
- **Docker Desktop** (con Docker Compose incluido)
- **Minikube** (para Kubernetes local) - [Instalar aqu√≠](https://minikube.sigs.k8s.io/docs/start/)
- **kubectl** - [Instalar aqu√≠](https://kubernetes.io/docs/tasks/tools/)

---

## üê≥ OPCI√ìN 1: Ejecuci√≥n Local con Docker Compose (M√°s F√°cil)

Esta opci√≥n demuestra la **paralelizaci√≥n** con m√∫ltiples processors.

### Paso 1: Clonar el repositorio
```powershell
git clone -b final_ver https://github.com/Jamh4949/News-COLCAP-Correlation-System.git
cd News-COLCAP-Correlation-System
```

### Paso 2: Construir las im√°genes Docker
```powershell
docker-compose build
```

### Paso 3: Levantar con 3 processors paralelos
```powershell
docker-compose up -d --scale processor=3
```

### Paso 4: Verificar que todo est√° corriendo
```powershell
docker-compose ps
```
Deber√≠as ver algo como:
```
NAME                    STATUS    PORTS
proyecto-api-1          running   0.0.0.0:8000->8000/tcp
proyecto-collector-1    running
proyecto-processor-1    running
proyecto-processor-2    running
proyecto-processor-3    running   <-- ¬°3 processors paralelos!
proyecto-analyzer-1     running
proyecto-postgres-1     running   0.0.0.0:5432->5432/tcp
proyecto-redis-1        running   0.0.0.0:6379->6379/tcp
```

### Paso 5: Ver la paralelizaci√≥n en acci√≥n
```powershell
# Ver logs de los 3 processors procesando simult√°neamente
docker-compose logs -f processor
```
Deber√≠as ver logs de `processor-1`, `processor-2`, `processor-3` procesando art√≠culos al mismo tiempo con mensajes como:
- `üîí Obtenidos X art√≠culos (con bloqueo distribuido)`
- `‚úÖ Batch de X art√≠culos procesado en X.XXs`

### Paso 6: Acceder al Dashboard y M√©tricas
```powershell
# Abrir Dashboard
start http://localhost:8000

# Ver m√©tricas Prometheus
start http://localhost:8000/metrics
```

### Paso 7: Detener todo
```powershell
docker-compose down
```

---

## ‚ò∏Ô∏è OPCI√ìN 2: Ejecuci√≥n con Kubernetes (Minikube)

Esta opci√≥n demuestra **Kubernetes completo**: HPA, PDB, CronJobs, m√∫ltiples r√©plicas.

### Paso 1: Clonar el repositorio
```powershell
git clone -b final_ver https://github.com/Jamh4949/News-COLCAP-Correlation-System.git
cd News-COLCAP-Correlation-System
```

### Paso 2: Iniciar Minikube
```powershell
minikube start --memory=4096 --cpus=2
```

### Paso 3: Configurar Docker para usar el de Minikube
```powershell
# Esto hace que las im√°genes se construyan dentro de Minikube
minikube docker-env --shell powershell | Invoke-Expression
```

### Paso 4: Construir las im√°genes
```powershell
docker build -t newscolcap/collector:latest ./services/collector
docker build -t newscolcap/processor:latest ./services/processor
docker build -t newscolcap/analyzer:latest ./services/analyzer
docker build -t newscolcap/api:latest ./services/api
```

### Paso 5: Crear el PVC con StorageClass correcto
```powershell
# El PVC necesita StorageClass "standard" en Minikube
@"
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-pvc
  namespace: news-colcap
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: standard
"@ | Set-Content -Path k8s/03-postgres-pvc-minikube.yaml

# Aplicar namespace primero
kubectl apply -f k8s/00-namespace.yaml

# Aplicar PVC para minikube
kubectl apply -f k8s/03-postgres-pvc-minikube.yaml
```

### Paso 6: Desplegar todos los servicios
```powershell
kubectl apply -f k8s/01-configmap.yaml
kubectl apply -f k8s/02-secrets.yaml
kubectl apply -f k8s/04-postgres.yaml
kubectl apply -f k8s/05-redis.yaml
kubectl apply -f k8s/06-collector.yaml
kubectl apply -f k8s/07-processor.yaml
kubectl apply -f k8s/08-analyzer.yaml
kubectl apply -f k8s/09-api.yaml
```

### Paso 7: Verificar que todo est√° corriendo
```powershell
kubectl get pods -n news-colcap
```
Deber√≠as ver:
```
NAME                         READY   STATUS    
analyzer-xxx                 1/1     Running
api-xxx                      1/1     Running
api-yyy                      1/1     Running   <-- 2 r√©plicas (HPA)
collector-xxx                1/1     Running
postgres-xxx                 1/1     Running
processor-xxx                1/1     Running
processor-yyy                1/1     Running
processor-zzz                1/1     Running   <-- 3 r√©plicas paralelas
redis-xxx                    1/1     Running
```

### Paso 8: Ver HPA y PDB
```powershell
# HorizontalPodAutoscaler - escala autom√°ticamente
kubectl get hpa -n news-colcap

# PodDisruptionBudget - alta disponibilidad
kubectl get pdb -n news-colcap
```

### Paso 9: Ver logs de processors paralelos
```powershell
kubectl logs -n news-colcap -l app=processor --tail=20
```

### Paso 10: Acceder al Dashboard
```powershell
# En una terminal separada, mantener corriendo:
kubectl port-forward svc/api-service 8080:8000 -n news-colcap

# Luego abrir en el navegador:
start http://localhost:8080
start http://localhost:8080/metrics
```

### Paso 11: Detener Minikube
```powershell
minikube stop

# O eliminar completamente:
minikube delete
```

---

## üìä Verificaci√≥n de Caracter√≠sticas

### ‚úÖ Paralelizaci√≥n (verificar en logs)
| Caracter√≠stica | D√≥nde verlo | Qu√© buscar |
|---------------|-------------|------------|
| **3 Processors paralelos** | `docker-compose ps` o `kubectl get pods` | 3 instancias de processor |
| **ThreadPoolExecutor** | Logs del processor | `ThreadPoolExecutor con X workers` |
| **Bloqueo distribuido** | Logs del processor | `üîí Obtenidos X art√≠culos (con bloqueo distribuido)` |
| **Batch Inserts** | Logs del collector | `‚úÖ Batch de X noticias guardadas` |

### ‚úÖ Kubernetes (verificar con kubectl)
| Caracter√≠stica | Comando | Qu√© ver |
|---------------|---------|---------|
| **HPA** | `kubectl get hpa -n news-colcap` | processor-hpa, api-hpa |
| **PDB** | `kubectl get pdb -n news-colcap` | processor-pdb, api-pdb |
| **CronJob** | `kubectl get cronjob -n news-colcap` | analyzer-cron |
| **M√∫ltiples r√©plicas** | `kubectl get pods -n news-colcap` | 3 processors, 2 APIs |

---

## üìä Servicios

### 1. Collector Service
- Recolecta noticias de GDELT cada 6 horas
- **BATCH INSERT**: Inserta 500 registros por operaci√≥n
- Filtra noticias relacionadas con Colombia

### 2. Processor Service (Paralelo)
- **ThreadPoolExecutor**: An√°lisis de sentimiento multi-thread (32+ threads)
- **FOR UPDATE SKIP LOCKED**: Bloqueo distribuido para pods m√∫ltiples
- **BATCH UPDATE**: Actualiza 100 registros por operaci√≥n
- Escala autom√°ticamente de 2 a 6 pods (HPA)

### 3. Analyzer Service (Paralelo)
- **ThreadPoolExecutor**: Fetch paralelo Yahoo Finance + BD
- Calcula correlaciones Pearson/Spearman
- CronJob para an√°lisis programado cada 6 horas

### 4. API & Dashboard
- Endpoints REST para consultas
- **Endpoint /metrics**: Formato Prometheus
- Visualizaci√≥n de correlaciones
- Escala autom√°ticamente de 2 a 5 pods (HPA)

---

## üìà M√©tricas Prometheus

Accede a `http://localhost:8000/metrics` (Docker) o `http://localhost:8080/metrics` (K8s) para ver:
```
news_colcap_news_total          # Total de noticias recolectadas
news_colcap_news_processed      # Noticias con an√°lisis de sentimiento
news_colcap_news_pending        # Noticias pendientes de procesar
news_colcap_sentiment_positive  # Noticias positivas
news_colcap_sentiment_negative  # Noticias negativas
news_colcap_sentiment_average   # Sentimiento promedio
news_colcap_colcap_price        # Precio COLCAP actual
news_colcap_redis_up            # Estado de Redis
```

---

## üîß Comandos √ötiles

### Docker Compose
```powershell
docker-compose ps              # Ver servicios
docker-compose logs -f         # Ver todos los logs
docker-compose logs -f processor  # Solo logs de processors
docker-compose down            # Apagar todo
```

### Kubernetes
```powershell
kubectl get all -n news-colcap           # Ver todos los recursos
kubectl get pods -n news-colcap          # Ver pods
kubectl get hpa -n news-colcap           # Ver autoescalado
kubectl logs -l app=processor -n news-colcap  # Logs de processors
kubectl scale deployment processor --replicas=5 -n news-colcap  # Escalar manualmente
```

---

## üë• Equipo

- Jose Armando Mart√≠nez Hern√°ndez - 2325365

## üìÑ License

This project is **dual-licensed**:

- **Non-commercial use** is allowed with attribution.
- **Commercial use** requires a separate license and may be subject to fees or royalties.

See the [LICENSE](./LICENSE) file for details.
